{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker.session.Session().default_bucket()\n",
    "\n",
    "\n",
    "# Change these to reflect your project/business name or if you want to separate ModelPackageGroup/Pipeline from the rest of your team\n",
    "model_package_group_name = f\"sm-mnist-p-jyytsuwy4oxn\"\n",
    "pipeline_name = f\"sm-mnist-pipeline-notebook\"\n",
    "base_job_prefix = \"sm-mnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_hop False:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class JsonGet has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from pipelines.mnist.pipeline import get_pipeline\n",
    "\n",
    "pipeline = get_pipeline(\n",
    "    region=region,\n",
    "    role=role,\n",
    "    default_bucket=default_bucket,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    pipeline_name=pipeline_name,\n",
    "    base_job_prefix=base_job_prefix,\n",
    "    use_hpo=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipelines/mnist/preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./pipelines/mnist/preprocess.py\n",
    "\"\"\"Prepare Mnist Dataset\"\"\"\n",
    "import argparse\n",
    "import logging\n",
    "import pathlib\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.system(\"pwd\")\n",
    "    logger.debug(\"Starting preprocessing.\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--arg\", type=str, required=False)\n",
    "    args = parser.parse_args()\n",
    "    arg = args.arg\n",
    "    \n",
    "    logger.debug(\"Defining transforms\")\n",
    "    mnist_transform = transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.5,), (1.0,))\n",
    "    ])\n",
    "    \n",
    "    base_dir = \"/opt/ml/processing\"\n",
    "\n",
    "    logger.debug(\"Downloading and applying transforms\")\n",
    "    MNIST(f'{base_dir}/train', transform=mnist_transform, train=True, download=True)\n",
    "    MNIST(f'{base_dir}/test', transform=mnist_transform, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipelines/mnist/code/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./pipelines/mnist/code/model.py\n",
    "\"\"\"Pytorch Mnist Model\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipelines/mnist/code/dataloader.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./pipelines/mnist/code/dataloader.py\n",
    "\"\"\"Data Loader\"\"\"\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "def get_train_data_loader(batch_size, training_dir, is_distributed, **kwargs):\n",
    "    logger.info(\"Get train data loader\", training_dir)\n",
    "\n",
    "    mnist_transform = transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.5,), (1.0,))\n",
    "    ])\n",
    "    dataset = MNIST(training_dir, transform=mnist_transform, train=True)\n",
    "#     dataset = MNIST(\"./data\", transform=mnist_transform, train=True, download=True)\n",
    "    train_sampler = (\n",
    "        torch.utils.data.distributed.DistributedSampler(dataset) if is_distributed else None\n",
    "    )\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=train_sampler is None,\n",
    "        sampler=train_sampler,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def get_test_data_loader(test_batch_size, test_dir, **kwargs):\n",
    "    logger.info(\"Get test data loader\", test_dir)\n",
    "    mnist_transform = transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.5,), (1.0,))\n",
    "    ])\n",
    "    dataset = MNIST(test_dir, transform=mnist_transform, train=False)\n",
    "#     dataset = MNIST(\"./data\", transform=mnist_transform, train=False, download=True)\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=test_batch_size,\n",
    "        shuffle=True,\n",
    "        **kwargs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipelines/mnist/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./pipelines/mnist/train.py\n",
    "\"\"\"Train Mnist Model\"\"\"\n",
    "# Based on https://github.com/aws/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/pytorch_mnist/mnist.py\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "import torch.optim as optim\n",
    "\n",
    "from code.model import Net\n",
    "from code import dataloader\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "\n",
    "# Based on https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "def _average_gradients(model):\n",
    "    # Gradient averaging.\n",
    "    size = float(dist.get_world_size())\n",
    "    for param in model.parameters():\n",
    "        dist.all_reduce(param.grad.data, op=dist.reduce_op.SUM, group=0)\n",
    "        param.grad.data /= size\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    is_distributed = len(args.hosts) > 1 and args.backend is not None\n",
    "    logger.debug(\"Distributed training - {}\".format(is_distributed))\n",
    "    use_cuda = args.num_gpus > 0\n",
    "    logger.debug(\"Number of gpus available - {}\".format(args.num_gpus))\n",
    "    kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if is_distributed:\n",
    "        # Initialize the distributed environment.\n",
    "        world_size = len(args.hosts)\n",
    "        os.environ[\"WORLD_SIZE\"] = str(world_size)\n",
    "        host_rank = args.hosts.index(args.current_host)\n",
    "        dist.init_process_group(backend=args.backend, rank=host_rank, world_size=world_size)\n",
    "        logger.info(\n",
    "            \"Initialized the distributed environment: '{}' backend on {} nodes. \".format(\n",
    "                args.backend, dist.get_world_size()\n",
    "            )\n",
    "            + \"Current host rank is {}. Number of gpus: {}\".format(dist.get_rank(), args.num_gpus)\n",
    "        )\n",
    "\n",
    "    # set the seed for generating random numbers\n",
    "    torch.manual_seed(args.seed)\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "        \n",
    "    train_loader = dataloader.get_train_data_loader(args.batch_size, args.train, is_distributed, **kwargs)\n",
    "    test_loader = dataloader.get_test_data_loader(args.test_batch_size, args.test, **kwargs)\n",
    "\n",
    "    logger.debug(\n",
    "        \"Processes {}/{} ({:.0f}%) of train data\".format(\n",
    "            len(train_loader.sampler),\n",
    "            len(train_loader.dataset),\n",
    "            100.0 * len(train_loader.sampler) / len(train_loader.dataset),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    logger.debug(\n",
    "        \"Processes {}/{} ({:.0f}%) of test data\".format(\n",
    "            len(test_loader.sampler),\n",
    "            len(test_loader.dataset),\n",
    "            100.0 * len(test_loader.sampler) / len(test_loader.dataset),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model = Net().to(device)\n",
    "    if is_distributed and use_cuda:\n",
    "        # multi-machine multi-gpu case\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model)\n",
    "    else:\n",
    "        # single-machine multi-gpu case or single-machine or multi-machine cpu case\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader, 1):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            running_loss = 0\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            running_loss += loss.item()\n",
    "            if is_distributed and not use_cuda:\n",
    "                # average gradients manually for multi-machine cpu case only\n",
    "                _average_gradients(model)\n",
    "            optimizer.step()\n",
    "        logger.info(\"Train Epoch: {} - Train Loss: {:.6f}\".format(epoch, running_loss/len(train_loader.dataset)))\n",
    "        test(model, test_loader, device)\n",
    "    save_model(model, args.model_dir)\n",
    "\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()  # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    logger.info(\n",
    "        \"Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "            test_loss, correct, len(test_loader.dataset), 100.0 * correct / len(test_loader.dataset)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.nn.DataParallel(Net())\n",
    "    with open(os.path.join(model_dir, \"model.pth\"), \"rb\") as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "def save_model(model, model_dir):\n",
    "    logger.info(\"Saving the model to \", model_dir)\n",
    "    path = os.path.join(model_dir, \"model.pth\")\n",
    "    # recommended way from http://pytorch.org/docs/master/notes/serialization.html\n",
    "    torch.save(model.cpu().state_dict(), path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Data and model checkpoints directories\n",
    "    parser.add_argument(\n",
    "        \"--batch-size\",\n",
    "        type=int,\n",
    "        default=64,\n",
    "        metavar=\"N\",\n",
    "        help=\"input batch size for training (default: 64)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--test-batch-size\",\n",
    "        type=int,\n",
    "        default=1000,\n",
    "        metavar=\"N\",\n",
    "        help=\"input batch size for testing (default: 1000)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--epochs\",\n",
    "        type=int,\n",
    "        default=10,\n",
    "        metavar=\"N\",\n",
    "        help=\"number of epochs to train (default: 10)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr\", type=float, default=0.01, metavar=\"LR\", help=\"learning rate (default: 0.01)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--momentum\", type=float, default=0.5, metavar=\"M\", help=\"SGD momentum (default: 0.5)\"\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", type=int, default=1, metavar=\"S\", help=\"random seed (default: 1)\")\n",
    "    parser.add_argument(\n",
    "        \"--log-interval\",\n",
    "        type=int,\n",
    "        default=100,\n",
    "        metavar=\"N\",\n",
    "        help=\"how many batches to wait before logging training status\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--backend\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help=\"backend for distributed training (tcp, gloo on cpu and gloo, nccl on gpu)\",\n",
    "    )\n",
    "\n",
    "    # Container environment\n",
    "    parser.add_argument(\"--hosts\", type=list, default=json.loads(os.environ[\"SM_HOSTS\"]))\n",
    "    parser.add_argument(\"--current-host\", type=str, default=os.environ[\"SM_CURRENT_HOST\"])\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ[\"SM_MODEL_DIR\"])\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ[\"SM_CHANNEL_TRAIN\"])\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ[\"SM_CHANNEL_TEST\"])\n",
    "    parser.add_argument(\"--num-gpus\", type=int, default=os.environ[\"SM_NUM_GPUS\"])\n",
    "\n",
    "    train(parser.parse_args())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipelines/mnist/evaluate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./pipelines/mnist/evaluate.py\n",
    "\"\"\"Evaluation script for measuring mean squared error.\"\"\"\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import logging\n",
    "import pathlib\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from code.model import Net\n",
    "from code import dataloader\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()  # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100.0 * correct / len(test_loader.dataset)\n",
    "    logger.info(\n",
    "        \"Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "            test_loss, correct, len(test_loader.dataset), 100.0 * correct / len(test_loader.dataset)\n",
    "        )\n",
    "    )\n",
    "    return test_loss, accuracy\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.nn.DataParallel(Net())\n",
    "    with open(os.path.join(model_dir, \"model.pth\"), \"rb\") as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.debug(\"Starting evaluation.\")\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--test-batch-size\",\n",
    "        type=int,\n",
    "        default=1000,\n",
    "        metavar=\"N\",\n",
    "        help=\"input batch size for testing (default: 1000)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--test\",\n",
    "        type=str,\n",
    "        default=\"/opt/ml/processing/test\",\n",
    "        help=\"input batch size for testing (default: 1000)\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    model_path = \"/opt/ml/processing/model/model.tar.gz\"\n",
    "    with tarfile.open(model_path) as tar:\n",
    "        tar.extractall(path=\".\")\n",
    "\n",
    "    logger.debug(\"Loading MNIST model.\")\n",
    "    model = model_fn(\"./\")\n",
    "\n",
    "    logger.debug(\"Reading test data.\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    testloader = dataloader.get_test_data_loader(args.test_batch_size, args.test)\n",
    "\n",
    "    logger.info(\"Calculating nll loss, accuracy of predictions against test data.\")\n",
    "    nll_loss, accuracy = test(model, testloader, device)\n",
    "    \n",
    "\n",
    "    report_dict = {\n",
    "        \"classification_metrics\": {\n",
    "            \"nll_loss\": {\n",
    "                \"value\": nll_loss\n",
    "            },\n",
    "            \"accuracy\": {\n",
    "                \"value\": accuracy\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    logger.info(\"Writing out evaluation report with nll loss: %f\", nll_loss)\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:ap-northeast-2:238312515155:pipeline/sm-mnist-pipeline-notebook',\n",
       " 'ResponseMetadata': {'RequestId': '4369f2df-e5e2-4e76-8ed4-836aeef9d9da',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '4369f2df-e5e2-4e76-8ed4-836aeef9d9da',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '99',\n",
       "   'date': 'Wed, 09 Feb 2022 02:33:13 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:ap-northeast-2:238312515155:pipeline/sm-mnist-pipeline-notebook',\n",
       " 'PipelineExecutionArn': 'arn:aws:sagemaker:ap-northeast-2:238312515155:pipeline/sm-mnist-pipeline-notebook/execution/qc9yg6iux9vj',\n",
       " 'PipelineExecutionDisplayName': 'execution-1644365058158',\n",
       " 'PipelineExecutionStatus': 'Executing',\n",
       " 'PipelineExperimentConfig': {'ExperimentName': 'sm-mnist-pipeline-notebook',\n",
       "  'TrialName': 'qc9yg6iux9vj'},\n",
       " 'CreationTime': datetime.datetime(2022, 2, 9, 0, 4, 18, 88000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2022, 2, 9, 0, 4, 18, 88000, tzinfo=tzlocal()),\n",
       " 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:ap-northeast-2:238312515155:user-profile/d-selnllxb1l52/shimdx-010',\n",
       "  'UserProfileName': 'shimdx-010',\n",
       "  'DomainId': 'd-selnllxb1l52'},\n",
       " 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:ap-northeast-2:238312515155:user-profile/d-selnllxb1l52/shimdx-010',\n",
       "  'UserProfileName': 'shimdx-010',\n",
       "  'DomainId': 'd-selnllxb1l52'},\n",
       " 'ResponseMetadata': {'RequestId': '7642318b-5fd2-4263-9e4b-20f80ed21845',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '7642318b-5fd2-4263-9e4b-20f80ed21845',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '853',\n",
       "   'date': 'Wed, 09 Feb 2022 00:04:20 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Create a low-level client representing Amazon SageMaker Runtime\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\", region_name=<aws_region>)\n",
    "\n",
    "# The name of the endpoint. The name must be unique within an AWS Region in your AWS account. \n",
    "endpoint_name='sm-mnist-staging'\n",
    "\n",
    "# After you deploy a model into production using SageMaker hosting \n",
    "# services, your client applications use this API to get inferences \n",
    "# from the model hosted at the specified endpoint.\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "                            EndpointName=endpoint_name, \n",
    "                            Body=bytes('{\"features\": [\"This is great!\"]}', 'utf-8') # Replace with your own data.\n",
    "                            )\n",
    "\n",
    "# Optional - Print the response body and decode it so it is human read-able.\n",
    "print(response['Body'].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name='sm-mnist-staging'\n",
    "sagemaker_session=sagemaker.session.Session()\n",
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "encoding without a string argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a6f15d236493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: encoding without a string argument"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5,), (1.0,))\n",
    "])\n",
    "testset = MNIST(\"./data\", transform=mnist_transform, train=False, download=True)\n",
    "\n",
    "\n",
    "results = predictor.predict(bytes(testset, 'utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-2:806072073708:image/1.8.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
